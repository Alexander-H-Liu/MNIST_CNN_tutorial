{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Using keras, a well known deep learning framework.\n",
    "# It's suitable for ppl who are new to deep learning (since it is a high level api)\n",
    "import keras\n",
    "\n",
    "# Import the components we're about to use\n",
    "from keras.layers import Conv2D,MaxPooling2D,Activation,Flatten,Dense\n",
    "\n",
    "# import mnist dataset using keras's api\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# toolkit for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# image shape of MNIST\n",
    "image_shape = (28,28,1)\n",
    "\n",
    "# Parameters for the model we're about to build\n",
    "# Modify these values as you like!\n",
    "layer_1_filters = 9\n",
    "layer_1_kernel_size = 2\n",
    "layer_2_filters = 9\n",
    "layer_2_kernel_size = 2\n",
    "nn_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "MNIST : handwritten digit dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tMNSIT Dataset\t\t\n",
      "Training set size :\t 60000\n",
      "Testing set size :\t 10000\n",
      "\t\tImage Demo\t\t\n",
      "Training image No. 0 (label= 5 )\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11196d438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load MNIST\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# Normalize the image\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Meta data of MNIST\n",
    "print('\\t\\tMNSIT Dataset\\t\\t')\n",
    "print('Training set size :\\t',len(x_train))\n",
    "print('Testing set size :\\t',len(x_test))\n",
    "\n",
    "# Display the an instance in our training set\n",
    "print('\\t\\tImage Demo\\t\\t')\n",
    "index = 0\n",
    "_ = plt.imshow(x_train[index],cmap='gray')\n",
    "_ = plt.axis('off')\n",
    "print('Training image No.',index,'(label=',y_train[index],')')\n",
    "\n",
    "# Pick a test image for demo\n",
    "test_index = 0\n",
    "test_image = x_test[test_index]\n",
    "test_label = y_test[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model\n",
    "Convolution Nerual Network for MNIST digit classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tOverview of Our CNN Model\t\t\t\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 27, 27, 9)         45        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 9)         0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 13, 13, 9)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 9)         333       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 9)           0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 6, 6, 9)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 324)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                10400     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 11,108\n",
      "Trainable params: 11,108\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Using sequential model (strait forward pipeline with single input/output) from keras\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# Add convolution layers to our model\n",
    "model.add(Conv2D(layer_1_filters,layer_1_kernel_size,input_shape=image_shape))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(layer_2_filters,layer_2_kernel_size))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten()) # reshape a n*n*depth image to a vector with dimension = n*n*depth\n",
    "model.add(Dense(nn_size,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print('\\t\\t\\tOverview of Our CNN Model\\t\\t\\t')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model\n",
    "We train our CNN model with the training data from MNIST for 2 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 17s 289us/step - loss: 0.3112 - acc: 0.9062\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 17s 292us/step - loss: 0.1117 - acc: 0.9652\n"
     ]
    }
   ],
   "source": [
    "# Reshape input (specified image depth for keras cnn)\n",
    "x_train = x_train.reshape(-1,28,28,1)\n",
    "# one-hot encoding label for as the target of model\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "\n",
    "_ = model.fit(x = x_train, y = y_train, epochs = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model\n",
    "Verfy the performance of our CNN model with the testing data from MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 140us/step\n",
      "Testing loss = 0.0853926225269\n",
      "Testing accuracy = 0.9731\n"
     ]
    }
   ],
   "source": [
    "x_test = x_test.reshape(-1,28,28,1)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "loss,acc = model.evaluate(x_test,y_test)\n",
    "print('Testing loss =',loss)\n",
    "print('Testing accuracy =',acc)\n",
    "\n",
    "pred_label = model.predict(x_test[test_index:test_index+1])[test_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing image No. 0 (label= 7 )\n",
      "Our model's prediction:\n",
      "\tlabel = 0 prob. = 0.0000%\n",
      "\tlabel = 1 prob. = 0.0000%\n",
      "\tlabel = 2 prob. = 0.0002%\n",
      "\tlabel = 3 prob. = 0.0000%\n",
      "\tlabel = 4 prob. = 0.0000%\n",
      "\tlabel = 5 prob. = 0.0000%\n",
      "\tlabel = 6 prob. = 0.0000%\n",
      "\tlabel = 7 prob. = 0.9998%\n",
      "\tlabel = 8 prob. = 0.0000%\n",
      "\tlabel = 9 prob. = 0.0000%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAABdlJREFUeJzt3c+LTX8cx/E5XyyUDaIs/CgrG/mRUqiRjViaf4GNbNSs7S1t/AU2SllIUhQLLMZCSGQskJQaC5RQ57v4bp33vd97Z+69c1+Px/Y1587ZPDuLz5y5Tdu2M0Cef8Z9A8B4iB9CiR9CiR9CiR9CiR9CiR9CiR9CiR9CrR3lL2uaxp8Twgpr27bp5+c8+SGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CGU+CHU2nHfwGoxNzfXuZ09e7a89tOnT+X+8+fPcr927Vq5f/78uXN7+/ZteS25PPkhlPghlPghlPghlPghlPghlPghVNO27eh+WdOM7pcts3fv3nVuu3btGt2N/MW3b986t5cvX47wTibLx48fO7fLly+X1y4sLCz37YxM27ZNPz/nyQ+hxA+hxA+hxA+hxA+hxA+hxA+hvM/fp+qd/b1795bXvnr1qtz37NlT7gcOHCj32dnZzu3w4cPltR8+fCj37du3l/sw/vz5U+5fvnwp923btg38u9+/f1/uq/mcv1+e/BBK/BBK/BBK/BBK/BBK/BBK/BDK+/xTYOPGjZ3bvn37ymufPn1a7ocOHRronvrR6/sK3rx5U+69/n5i06ZNndv58+fLa69evVruk8z7/EBJ/BBK/BBK/BBK/BBK/BBK/BDKOT8T68yZM+V+/fr1cn/x4kXndvz48fLapaWlcp9kzvmBkvghlPghlPghlPghlPghlKM+xmbr1q3l/vz586Gun5ub69xu3LhRXruaOeoDSuKHUOKHUOKHUOKHUOKHUOKHUL6im7Hp9e+zt2zZUu5fv34t99evX//ve0riyQ+hxA+hxA+hxA+hxA+hxA+hxA+hvM/Pijpy5Ejndv/+/fLadevWlfvs7Gy5P3z4sNynlff5gZL4IZT4IZT4IZT4IZT4IZT4IZT3+VlRp06d6tx6nePfu3ev3B8/fjzQPfEfT34IJX4IJX4IJX4IJX4IJX4IJX4I5Zyfoaxfv77cT5482bn9+vWrvPbSpUvl/vv373Kn5skPocQPocQPocQPocQPocQPoRz1MZT5+fly379/f+d2586d8tpHjx4NdE/0x5MfQokfQokfQokfQokfQokfQokfQvmKbkqnT58u95s3b5b7jx8/Orfqdd+ZmZmZJ0+elDt/5yu6gZL4IZT4IZT4IZT4IZT4IZT4IZT3+cNt3ry53K9cuVLua9asKffbt293bs7xx8uTH0KJH0KJH0KJH0KJH0KJH0KJH0J5n3/K9TqH73XWfvDgwXJfXFws9+qd/V7XMhjv8wMl8UMo8UMo8UMo8UMo8UMor/ROud27d5d7r6O8Xi5evFjujvMmlyc/hBI/hBI/hBI/hBI/hBI/hBI/hHLOPwV27tzZud29e3eoz56fny/3W7duDfX5jI8nP4QSP4QSP4QSP4QSP4QSP4QSP4Ryzj8Fzp0717nt2LFjqM9+8OBBuY/yX7+zvDz5IZT4IZT4IZT4IZT4IZT4IZT4IZRz/lXg6NGj5X7hwoUR3QnTxJMfQokfQokfQokfQokfQokfQokfQjnnXwWOHTtW7hs2bBj4sxcXF8v9+/fvA382k82TH0KJH0KJH0KJH0KJH0KJH0I56ptyz549K/cTJ06U+9LS0nLeDhPEkx9CiR9CiR9CiR9CiR9CiR9CiR9CNaP8iuWmaXyfM6ywtm2bfn7Okx9CiR9CiR9CiR9CiR9CiR9CiR9CjfScH5gcnvwQSvwQSvwQSvwQSvwQSvwQSvwQSvwQSvwQSvwQSvwQSvwQSvwQSvwQSvwQSvwQSvwQSvwQSvwQSvwQSvwQSvwQSvwQ6l/9jO48zyZIkAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120e4d978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Testing image No.',test_index,'(label=',test_label,')')\n",
    "_ = plt.imshow(test_image,cmap='gray')\n",
    "_ = plt.axis('off')\n",
    "print('Our model\\'s prediction:')\n",
    "for i in range(10):\n",
    "    print('\\tlabel =',i,'prob. = {:.4f}%'.format(pred_label[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
